# HW06 – Report

Файл: `homeworks/HW06/report.md`  

## 1. Dataset

- Какой датасет выбран: `S06-hw-dataset-01.csv`
- Размер: (12000, 30)
- Целевая переменная: `target` (классы и их доли): класс 0 — 67.66%, класс 1 — 32.34%
- Признаки: что за типы (числовые / категориальные-подобные, если есть):  
  24 числовых признака (`num01`–`num24`), 3 категориальных-подобных целочисленных признака (`cat_contract`, `cat_region`, `cat_payment`), 1 числовой признак `tenure_months`. Все признаки представлены как числа, пропусков нет.

## 2. Protocol

- Разбиение: train/test (доли, `random_state`): 80%/20%, `random_state=42`, с стратификацией по `target` для сохранения пропорций классов.
- Подбор: CV на train (сколько фолдов, что оптимизировали): 5-фолдовая кросс-валидация на `X_train`, оптимизация по `ROC-AUC`.
- Метрики: accuracy, F1, ROC-AUC (и почему эти метрики уместны именно здесь):  
  Accuracy — общая доля правильных ответов. F1 — гармоническое среднее точности и полноты, учитывает дисбаланс. ROC-AUC — оценивает качество ранжирования вероятностей, устойчив к умеренному дисбалансу. Все три метрики дают полную картину качества в бинарной задаче.

## 3. Models

Опишите, какие модели сравнивали и какие гиперпараметры подбирали.

Минимум:

- DummyClassifier (baseline): `strategy="most_frequent"` — всегда предсказывает класс 0.
- LogisticRegression (baseline из S05): `Pipeline(StandardScaler → LogisticRegression)`, обучена без подбора.
- DecisionTreeClassifier (контроль сложности: `max_depth` + `min_samples_leaf` или `ccp_alpha`): подбор `max_depth ∈ [3,5,7,10]`, `min_samples_leaf ∈ [10,20,50]`.
- RandomForestClassifier: подбор `max_depth ∈ [5,10,None]`, `min_samples_leaf ∈ [5,10,20]`, `max_features ∈ ['sqrt','log2']`.
- Один boosting (AdaBoost / GradientBoosting / HistGradientBoosting): `GradientBoostingClassifier`, подбор `n_estimators ∈ [100,200]`, `max_depth ∈ [2,3,4]`, `learning_rate ∈ [0.05,0.1,0.2]`.

Опционально:

- StackingClassifier (с CV-логикой): не использован.

## 4. Results

- Таблица/список финальных метрик на test по всем моделям:

| Модель               | Accuracy | F1     | ROC-AUC |
|----------------------|----------|--------|---------|
| DummyClassifier      | 0.6767   | 0.0000 | 0.5000  |
| LogisticRegression   | 0.8275   | 0.7076 | 0.8747  |
| DecisionTree         | 0.8683   | 0.7879 | 0.9067  |
| RandomForest         | 0.9225   | 0.8726 | 0.9648  |
| GradientBoosting     | 0.9267   | 0.8834 | 0.9670  |

- Победитель (по ROC-AUC или по согласованному критерию) и краткое объяснение:  
  Победителем стала **GradientBoostingClassifier** (ROC-AUC = **0.9670**). Она показала наивысшее качество ранжирования и баланс между точностью и полнотой (F1=0.8834), что делает её лучшим выбором для данной задачи.

## 5. Analysis

- Устойчивость: что будет, если поменять `random_state` (хотя бы 5 прогонов для 1-2 моделей) – кратко:  
  Не проверялось (опционально). Предположительно, метрики будут колебаться в пределах ±0.01, что типично для ансамблей.
- Ошибки: confusion matrix для лучшей модели + комментарий:  
  Confusion matrix (сохранена в `figures/`) показывает низкое число ошибок: большинство объектов классифицированы верно, включая редкий класс 1.
- Интерпретация: permutation importance (top-10/15) + выводы:  
  Топ-3 признака: `num18`, `num19`, `num07`. Все важные признаки — числовые, что соответствует синтетической природе данных. Категориальные признаки не вошли в топ-10, что может означать их меньшую предсказательную силу в этой генерации данных.

## 6. Conclusion

- Деревья без ограничений переобучаются, но контроль сложности (`max_depth`, `min_samples_leaf`) значительно улучшает обобщающую способность.
- Ансамбли (Random Forest, GradientBoosting) существенно превосходят как отдельные деревья, так и линейные модели.
- GradientBoosting показал наилучший результат, что подтверждает его силу в задачах бинарной классификации со сложной структурой признаков.
- Честный ML-протокол (фиксированный split, CV на train, single test evaluation) обеспечил воспроизводимость и объективное сравнение.
- ROC-AUC и F1 оказались гораздо информативнее accuracy при умеренном дисбалансе.
- Permutation importance — надёжный инструмент интерпретации, не зависящий от внутренней реализации модели.